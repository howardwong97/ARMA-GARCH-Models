{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Determination\n",
    "\n",
    "In the previous notebook, the assumed model was ARMA(1,1)-GARCH(1,1). However, we should account for additional lags in the ARMA component of the model. To do this, I implement a brute-force search for p and q in ARMA(p,q) and choose the order that maximizes log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def arma(c, phi, theta, r):\n",
    "    T = len(r)\n",
    "    epsilon = np.zeros(T)\n",
    "    for t in range(T):\n",
    "        if t < len(phi):\n",
    "            epsilon[t] = r[t] - np.mean(r)\n",
    "        else:\n",
    "            ar_sum = np.sum([phi[i] * r[t-1-i] for i in range(len(phi))])\n",
    "            ma_sum = np.sum([theta[i] * epsilon[t-1-i] for i in range(len(theta))])\n",
    "            epsilon[t] = r[t] - c - ar_sum - ma_sum\n",
    "    return epsilon\n",
    "\n",
    "\n",
    "def garch(omega, alpha, beta, epsilon):\n",
    "    T = len(epsilon)\n",
    "    sigma_2 = np.zeros(T)\n",
    "    for t in range(T):\n",
    "        if t == 0:\n",
    "            sigma_2[t] = omega / (1 - alpha - beta) # initialize as unconditional variance\n",
    "        else:\n",
    "            sigma_2[t] = omega + alpha*epsilon[t-1]**2 + beta*sigma_2[t-1]\n",
    "    return sigma_2\n",
    "\n",
    "\n",
    "def armagarch_negloglike(params, p, q, r):\n",
    "    T = len(r)\n",
    "    c = params[0] # (-10*mean, 10*mean)\n",
    "    phi = params[1:p+1]\n",
    "    theta = params[p+1:(p+q+2)] \n",
    "    omega = params[-3] # positive, (finfo.eps, 2*r.var())\n",
    "    alpha = params[-2]\n",
    "    beta = params[-1]\n",
    "    \n",
    "    epsilon = arma(c, phi, theta, r)\n",
    "    sigma_2 = garch(omega, alpha, beta, epsilon)\n",
    "    sigma_2 = np.where(sigma_2<=0, np.finfo(np.float64).eps, sigma_2)\n",
    "    NegLogL = -0.5 * np.sum(-np.log(sigma_2) - epsilon**2/sigma_2)\n",
    "    return NegLogL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def determine_order(r, max_p, max_q):\n",
    "    print('Running ARMA-GARCH Order Determination...')\n",
    "    finfo = np.finfo(np.float64)\n",
    "    temp_aic = np.inf\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    for q in range(1, max_q+1):\n",
    "        for p in range(1, max_p+1):\n",
    "                        \n",
    "            # Define bounds for c, phi, theta, omega, alpha, beta\n",
    "            c_bounds = [(-10*np.abs(np.mean(r)), 10*np.abs(np.mean(r)))]\n",
    "            phi_bounds = [(-0.99999999, 0.99999999) for i in range(p)]\n",
    "            theta_bounds = [(-0.99999999, 0.99999999) for i in range(q)]\n",
    "            omega_bounds = [(finfo.eps, 2 * np.var(r))]\n",
    "            alpha_bounds = [(finfo.eps, 0.99999999)]\n",
    "            beta_bounds = [(finfo.eps, 0.99999999)]\n",
    "            \n",
    "            bounds = c_bounds + phi_bounds + theta_bounds + omega_bounds + alpha_bounds + beta_bounds\n",
    "\n",
    "            initial_params =  tuple(0.0001 for _ in range(4+p+q))\n",
    "            cons = (\n",
    "                {'type': 'ineq', 'func': lambda x: x-finfo.eps},\n",
    "                {'type': 'ineq', 'func': lambda x: 1-x[-1]-x[-2]+0.00000000000001}\n",
    "            )\n",
    "            res = minimize(armagarch_negloglike, initial_params, args=(p, q, r), bounds=bounds, method='SLSQP')\n",
    "            neg_llh_val = res.fun\n",
    "            aic = 2 * len(initial_params) + 2 * neg_llh_val\n",
    "            if aic < temp_aic:\n",
    "                best_p = p\n",
    "                best_q = q\n",
    "                temp_aic = aic\n",
    "                print('Current best model: ARMA({},{})-GARCH(1,1), AIC = {}'.format(str(p), str(q), temp_aic))\n",
    "                \n",
    "    print('Order determination completed.')\n",
    "    print('p =', best_p)\n",
    "    print('q =', best_q)\n",
    "    print('AIC =', temp_aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ARMA-GARCH Order Determination...\n",
      "Current best model: ARMA(1,1)-GARCH(1,1), AIC = -21589.13214933066\n",
      "Current best model: ARMA(2,1)-GARCH(1,1), AIC = -21707.300379325097\n",
      "Order determination completed.\n",
      "p = 2\n",
      "q = 1\n",
      "AIC = -21707.300379325097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/top10_logreturns.csv', index_col=0, parse_dates=True)['D05.SI']  # scaled for ease of optimization\n",
    "determine_order(data.values, 6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "4",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
