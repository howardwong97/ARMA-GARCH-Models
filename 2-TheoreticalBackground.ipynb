{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical Background of ARMA-GARCH\n",
    "\n",
    "\n",
    "## Defining ARMA and GARCH\n",
    "\n",
    "The *autoregressive moving average* (ARMA) representation of a time series combines a stationary autoregressive (AR) model with a stationary moving-average error process (MA). The *generalised autoregressive conditional heteroscedasticity* (GARCH) model is made up of two equations - the conditional mean equation and the conditional variance equation. By representing the conditional mean equation as an ARMA process, \n",
    "\n",
    "\n",
    "## Unconditional vs. Conditional Values\n",
    "\n",
    "The unconditional mean and variance represents the mean and variance of the distribution and is assumed to be constant. On the other hand, the conditional mean and variance can change at every point in time, and hence depends on historical values (i.e. conditioned on past information). Volatility often forms in 'clusters', meaning that high volatility tends to be sustained over a certain time period. This forms the foundation of GARCH models.\n",
    "\n",
    "## Return Distributions\n",
    "\n",
    "(*from this point on, 'returns' refers to log-returns*)\n",
    "\n",
    "Let $\\mathcal{F_{t-1}}$ be the *filtration* of past returns, which is simply an *information set* of all of the observed past returns up to a time $t-1$. Let $r_t$ represent the series of log returns for $t=\\{1,\\dots,T\\}$. If the distribution of returns is assumed to be *Normal*, one can write\n",
    "\n",
    "\\begin{equation}\n",
    "    r_t \\vert \\mathcal{F_{t-1}} \\sim N(\\bar{r_t}, \\sigma_t^2),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\bar{r_t}$ is the conditional mean and $\\sigma_t^2$ represents the conditional variance of returns. However, while the returns are often assumed to follow a Normal distribution, this is not the case with our data, which exhibits clear leptokursis and skew. This leads to 'fat-tails' and skewness. Therefore, multiple distributions forming a set $D = \\{ d \\}$ are considered:\n",
    "\n",
    "- Normal Distribution (NORM)\n",
    "- Generalized Error Distribution (GED)\n",
    "- Student t Distribution (STD)\n",
    "- Skewed Normal Distribution (SNORM)\n",
    "- Skewed Generalised Error Distribution (SGED)\n",
    "- Skewed Student t Distribution (SSTD)\n",
    "- Generalized Hyperbolic Function Distribution (GHYP)\n",
    "- Generalized Hyperbolic Skewed Student tDistribution\n",
    "- Normal Inverse Gaussian Distribution (NIG)\n",
    "\n",
    "Subsequently, the Akaike information criteria (AIC) will be used to assess the quality of each model. The AIC penalises a high number of estimated parameters and is hence a good criteria to obtain a parsimonious model, balancing goodness of fit and the number of parameters:\n",
    "\n",
    "\\begin{equation}\n",
    "    AIC = 2k - 2\\ln(\\hat{L}),\n",
    "\\end{equation}\n",
    "\n",
    "where $k$ is the number of estimated parameters and $\\hat{L}$ is the maximum value of the likelihood function for the model.\n",
    "\n",
    "## Conditional Mean Equation: ARMA\n",
    "\n",
    "The conditional mean specifies the behaviour of the returns. In this case, we assume that the return series follows an ARMA model, which accounts for the possibility of autocorrelation and dependence on past error terms. The conditional mean equation is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "    r_t = c + \\sum_{i=1}^{p} \\phi_i r_{t-i} + \\sum_{i=1}^{q} \\theta_i \\epsilon_{t-i} + \\epsilon_t,\n",
    "\\end{equation}\n",
    "\n",
    "where $c$ is a constant term, $\\phi_i$ is the autoregressive coefficient, $\\theta_i$ is the moving coefficient and $\\epsilon_t$ is the *innovation* or *shock*. We allow for\n",
    "\n",
    "\\begin{equation}\n",
    "    \\epsilon_{t} \\vert \\mathcal{F_{t-1}} \\sim d(0, \\sigma_i^2), \\quad d\\subseteq D,\n",
    "\\end{equation}\n",
    "\n",
    "where $D$ is the set of distributions defined previously.\n",
    "\n",
    "## Conditional Variance Equation: GARCH\n",
    "\n",
    "GARCH is a generalisation of the ARCH model. The ARCH model allows for many lags in the conditional variance, and the GARCH model extends it by also allowing for lags in the error terms. It is essentially the ARMA model, but for the conditional variance instead of the conditional mean. The conditional variance equation is hence defined as\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sigma_t^2 = \\omega + \\sum_{i=1}^{q} \\alpha_i \\epsilon_{t-i}^2 + \\sum_{i=1}^{p} \\beta_i \\sigma_{t-i}^2,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\omega$ is a constant term, $\\alpha_i$ is the GARCH error parameter, and $\\beta_i$ is the autoregressive coefficient. In other words, $\\alpha_i$ measures the *reaction* of the conditional volatility to market shocks, and $\\beta_i$ measures the *persistence* of the conditional volatility. The parameters are constrained by:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\alpha + \\beta \\leq 1\n",
    "\\end{equation}\n",
    "\n",
    "for convergence. The sum $\\alpha + \\beta$ determines the rate of convergence of the conditional volatility to the long-term average level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "2",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
