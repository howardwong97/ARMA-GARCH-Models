{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARMA-GARCH Maximum Likelihood Estimation \n",
    "\n",
    "One possible approach of fitting an ARMA-GARCH model is to perform a maximum likelihood estimation (MLE) for the conditional mean (ARMA), then an MLE of the conditional variance (GARCH). However, joint estimation is preferred. In the first stage of ARMA estimation, there is an implicit assumption of conditional homoskedasticity. It is contradicted in the second stage when you explicitly model conditional heteroskedasticity using GARCH.\n",
    "\n",
    "## An Example: GARCH(1,1) with Normal Distribution\n",
    "\n",
    "Recall a GARCH(1,1) model is defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\sigma_t^2 = \\alpha_0 + \\alpha_1 \\epsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2,\n",
    "\\end{equation}\n",
    "\n",
    "and the *log-likelihood* function for a normally distributed random variable is:\n",
    "\n",
    "\\begin{equation}\n",
    "    L = - \\frac{1}{2} \\sum_{t=1}^T \\left( \\ln \\sigma_t^2 + \\left(\\frac{\\epsilon_{t}}{\\sigma_t} \\right)^2 \\right),\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def garch(alpha0, alpha1, beta1, epsilon):\n",
    "    T = len(epsilon)\n",
    "    sigma_2 = np.zeros(T)\n",
    "    \n",
    "    for t in range(T):\n",
    "        if t == 0:\n",
    "            sigma_2[t] = alpha0 / (1 - alpha1 - beta1) # initialize as unconditional variance\n",
    "        else:\n",
    "            sigma_2[t] = alpha0 + alpha1*epsilon[t-1]**2 + beta1*sigma_2[t-1]\n",
    "            \n",
    "    return sigma_2\n",
    "    \n",
    "def garch_neg_loglike(params, epsilon):\n",
    "    T = len(epsilon)\n",
    "    alpha0 = params[0]\n",
    "    alpha1 = params[1]\n",
    "    beta1 = params[2]\n",
    "    sigma_2 = garch(alpha0, alpha1, beta1, epsilon)\n",
    "    NegLogL = -0.5 * np.sum(-np.log(sigma_2) - epsilon**2/sigma_2)  # negative sign for minimization\n",
    "    return NegLogL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1514.9967534819598"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "data = pd.read_csv('data/top10_logreturns.csv', index_col=0, parse_dates=True)['D05.SI'] * 100  # scaled for ease of optimization\n",
    "bounds = tuple((0.0001, None) for i in range(3))\n",
    "params_initial = (0.1, 0.05, 0.92)\n",
    "cons = (\n",
    "    {'type': 'ineq', 'func': lambda x: np.array(x)},\n",
    "    {'type': 'ineq', 'func': lambda x: 1-x[1]-x[2]+0.00000000000001}\n",
    ")  \n",
    "\n",
    "res = minimize(garch_neg_loglike, params_initial, args=(data), bounds=bounds, options={'disp': True})\n",
    "res.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Example: ARMA(1,1) with Normal Distrbitution\n",
    "\n",
    "We utilise the same log-likelihood function defined above, but this time we use an ARMA(1,1) model,\n",
    "\n",
    "\\begin{equation}\n",
    "    \\epsilon_t = r_t - \\phi_0 - \\phi_1 r_{t-1} - \\theta_1 \\epsilon_{t-1},\n",
    "\\end{equation}\n",
    "\n",
    "which has been rearranged to solve for $\\epsilon_t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arma(phi0, phi1, theta1, r):\n",
    "    T = len(r)\n",
    "    epsilon = np.zeros(T)\n",
    "    \n",
    "    for t in range(T):\n",
    "        if t == 0:\n",
    "            epsilon[t] = r[t] - np.mean(r)\n",
    "        else:\n",
    "            epsilon[t] = r[t] - phi0 - phi1*r[t-1] - theta1*epsilon[t-1]\n",
    "    \n",
    "    return epsilon\n",
    "\n",
    "def arma_neg_loglike(params, r):\n",
    "    T = len(r)\n",
    "    phi0 = params[0]\n",
    "    phi1 = params[1]\n",
    "    theta1 = params[2]\n",
    "    epsilon = arma(phi0, phi1, theta1, r)\n",
    "    NegLogL = -0.5 * np.sum(-np.log(r.var()) - epsilon**2/r.var())\n",
    "    return NegLogL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting ARMA-GARCH with MLE\n",
    "\n",
    "Based on some preliminary research, many sources suggest estimating the *ARMA* process first, followed by modelling the innovations with GARCH. However, this will most likely lead to inconsistent parameter estimates. In fitting an ARMA model, there is an assumption made about the *conditional variance* - it is constant. This is clearly not the case when the process is assumed to follow that of GARCH. This is especially an issue when it comes to order determination for the ARMA model - the ACF and PACF confidence bounds will be invalid given the GARCH-type residuals. \n",
    "\n",
    "Therefore, parameter determination via MLE must be performed for both ARMA and GARCH *simultaneously*. This simply involves substituting the *conditional mean* component from ARMA and the *conditional variance* component from GARCH into the log-likelihood equation and minimizing with `scipy`. We should also account for additional lags in the ARMA component of the model. To do this, I implement a brute-force search for p and q in ARMA(p,q) and choose the order that maximizes log-likelihood.\n",
    "\n",
    "Checkout `armagarch.py` for the VaR model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import armagarch as ag\n",
    "\n",
    "model = ag.VaRModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c6c4f9945c541c48871b78cc83c503b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best: ARMA(0,0)-GARCH(1,1), AIC = 8050.785085605261\n",
      "Current best: ARMA(0,1)-GARCH(1,1), AIC = 8044.969154630786\n",
      "\n",
      "Order determination complete with p = 0 and q = 1\n",
      "AIC = 8044.969154630786\n",
      "Parameter   Estimate       Std. Err.      T-stat     p-value\n",
      "c           0.053232        0.019489     2.73137     0.00635\n",
      "theta0      0.059114        0.022267     2.65475     0.00798\n",
      "omega       0.057600        0.037966     1.51716     0.12934\n",
      "alpha       0.133531        0.051933     2.57123     0.01019\n",
      "beta        0.826876        0.074948     11.03270     0.00000\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('data/top10_logreturns.csv', index_col=0, parse_dates=True)['D05.SI'].values\n",
    "model.fit(X, max_p=3, max_q=3, verbose=True, summary_stats=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Students t-distribution\n",
    "\n",
    "The Student's t-distribution has a density function:\n",
    "\n",
    "\\begin{equation}\n",
    "f(\\epsilon) = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1 + \\frac{\\epsilon_t^2}{(\\nu-2)\\sigma_t^2}\\right)^{-\\frac{(\\nu+1}{2}},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Gamma$ is the gamma function defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Gamma(z) = \\int_0^{\\infty} t^{z-1} e^{-t} dt,\n",
    "\\end{equation}\n",
    "\n",
    "and $\\nu > 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db77542b4f1e41c0a4400eb8061585e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current best: ARMA(0,0)-GARCH(1,1), AIC = 8015.785461729878\n",
      "Current best: ARMA(0,1)-GARCH(1,1), AIC = 8011.933621923644\n",
      "Current best: ARMA(1,1)-GARCH(1,1), AIC = 8011.156622933455\n",
      "\n",
      "Order determination complete with p = 1 and q = 1\n",
      "AIC = 8011.156622933455\n",
      "Parameter   Estimate       Std. Err.      T-stat     p-value\n",
      "c           0.075817        0.031224     2.42814     0.01524\n",
      "phi0        -0.657009        0.163684     4.01389     0.00006\n",
      "theta0      0.699807        0.154447     4.53106     0.00001\n",
      "omega       0.127998        0.052444     2.44066     0.01472\n",
      "alpha       0.165976        0.051873     3.19968     0.00139\n",
      "beta        0.822651        0.055870     14.72436     0.00000\n",
      "v           3.000000        0.073827     40.63547     0.00000\n"
     ]
    }
   ],
   "source": [
    "t_model = ag.VaRModel(llh_func='t')\n",
    "t_model.fit(X, max_p=2, max_q=2, verbose=True, summary_stats=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "3",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
